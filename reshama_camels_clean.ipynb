{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```text\n",
      "=== Software === \n",
      "python version  : 3.6.5\n",
      "fastai version  : 1.0.14\n",
      "torch version   : 1.0.0.dev20181022\n",
      "nvidia driver   : 396.44\n",
      "torch cuda ver  : 9.2.148\n",
      "torch cuda is   : available\n",
      "torch cudnn ver : 7104\n",
      "torch cudnn is  : enabled\n",
      "\n",
      "=== Hardware === \n",
      "nvidia gpus     : 1\n",
      "torch available : 1\n",
      "  - gpu0        : 7611MB | Tesla P4\n",
      "\n",
      "=== Environment === \n",
      "platform        : Linux-4.9.0-8-amd64-x86_64-with-debian-9.5\n",
      "distro          : #1 SMP Debian 4.9.110-3+deb9u6 (2018-10-08)\n",
      "conda env       : Unknown\n",
      "python          : /opt/anaconda3/bin/python\n",
      "sys.path        : \n",
      "/opt/anaconda3/lib/python36.zip\n",
      "/opt/anaconda3/lib/python3.6\n",
      "/opt/anaconda3/lib/python3.6/lib-dynload\n",
      "/opt/anaconda3/lib/python3.6/site-packages\n",
      "/opt/anaconda3/lib/python3.6/site-packages/IPython/extensions\n",
      "/home/jupyter/.ipython\n",
      "```\n",
      "\n",
      "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
      "\n",
      "Optional package(s) to enhance the diagnostics can be installed with:\n",
      "pip install distro\n",
      "Once installed, re-run this utility to get the additional information\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.show_install(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Creating your own dataset from Google Images\n",
    "\n",
    "*by: Francisco Ingham and Jeremy Howard. Inspired by [Adrian Rosebrock](https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "In this tutorial we will see how to easily create an image dataset through Google Images. **Note**: You will have to repeat these steps for any new category you want to Google (e.g once for dogs and once for cats)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and scroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [Google Images](http://images.google.com) and search for the images you are interested in. The more specific you are in your Google Search, the better the results and the less manual pruning you will have to do.\n",
    "\n",
    "Scroll down until you see a button that says 'Show more results'. All the images you scrolled past are now available to download. To get more, click on the button. Then continue scrolling until you cannot scroll anymore. The maximum number of images Google Images shows is 700."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download into file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you must run some Javascript code in your browser which will save the URLs of all the images you want for you dataset.\n",
    "\n",
    "Press <kbd>Ctrl</kbd><kbd>Shift</kbd><kbd>J</kbd> in Windows/Linux and <kbd>Cmd</kbd><kbd>Opt</kbd><kbd>J</kbd> in Mac, and a small window the javascript 'Console' will appear. That is where you will paste the JavaScript commands.\n",
    "\n",
    "You will need to get the urls of each of the images. You can do this by running the following commands:\n",
    "\n",
    "```javascript\n",
    "urls = Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou);\n",
    "window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory and upload urls file into your server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Choose an appropriate name for your labeled images. You can run these steps multiple times to grab different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = \"/home/jupyter/tutorials/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'camels'\n",
    "file = 'urls_camels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(my_path+'data/mammals')\n",
    "dest = path/folder\n",
    "dest.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'horses'\n",
    "file = 'urls_horses.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(my_path+'data/mammals')\n",
    "dest = path/folder\n",
    "dest.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, upload your urls file. You just need to press Upload in your working directory and select your file, then click 'upload' on the right.\n",
    "\n",
    "![](images/download_images/upload.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will need to download you images from their respective urls.\n",
    "\n",
    "fast.ai has a function that allows you to do just that. You just have to specify the urls filename and the destination folder and this function will download and save all images than can be opened. If they have some problem in being opened, they will not be saved.\n",
    "\n",
    "Let's download our images! Notice you can choose a maximum number of images to be downloaded. In this case we will not download all the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = \"/home/jupyter/tutorials/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/commons/d/de/Nokota_Horses_cropped.jpg\r\n",
      "https://equusmagazine.com/.image/t_share/MTQ1Mjc2NDE4Mzk1MjE5MzUy/feral-horse-and-foal-walk-along-the-beach-on-vieques-island-off-puerto-rico.jpg\r\n",
      "https://i.ytimg.com/vi/_Yz0VL0GsNM/hqdefault.jpg\r\n",
      "https://media.treehugger.com/assets/images/2018/02/three-horses.jpg.860x0_q70_crop-scale.jpg\r\n",
      "https://www.equinenow.com/content/american-quarter-horse.jpg\r\n",
      "https://www.sciencenews.org/sites/default/files/2018/02/main/articles/022118_EE_horses_feat.jpg\r\n",
      "https://thehorse.com/wp-content/uploads/2017/09/paint-horse-running-in-field.jpg\r\n",
      "https://www.aspca.org/sites/default/files/blog_072117_house-senate-vote-horse-slaughter_main_1.jpg\r\n",
      "https://i.redd.it/a6me53rp6ha01.jpg\r\n",
      "https://i.ytimg.com/vi/y1U1Eqfdg7w/maxresdefault.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!head {my_path}data/mammals/urls_horses.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='200' max='200', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [200/200 00:08<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error https://www.thenational.ae/image/policy:1.695004:1515936024/image/jpeg.jpg?f=16x9&w=1200&$p$f$w=dfa40e8 'content-length'\n",
      "Error 80/1920698/image.jpg Invalid URL '80/1920698/image.jpg': No schema supplied. Perhaps you meant http://80/1920698/image.jpg?\n",
      "Error https://www.giladorigami.com/P_Camel_Montroll.JPG 'content-length'\n",
      "Error f_auto Invalid URL 'f_auto': No schema supplied. Perhaps you meant http://f_auto?\n",
      "Error fl_progressive Invalid URL 'fl_progressive': No schema supplied. Perhaps you meant http://fl_progressive?\n",
      "Error q_80 Invalid URL 'q_80': No schema supplied. Perhaps you meant http://q_80?\n",
      "Error w_800/19cmjjuv9x7lajpg.jpg Invalid URL 'w_800/19cmjjuv9x7lajpg.jpg': No schema supplied. Perhaps you meant http://w_800/19cmjjuv9x7lajpg.jpg?\n",
      "Error http://www.zendmentravel.com/wp-content/uploads/2016/04/IMG_1016-1.jpg 'content-length'\n",
      "Error https://www.thenational.ae/image/policy:1.646140:1506086604/image/jpeg.jpg?f=16x9&w=1200&$p$f$w=dfa40e8 'content-length'\n",
      "Error h_1550 Invalid URL 'h_1550': No schema supplied. Perhaps you meant http://h_1550?\n",
      "Error c_limit/camels-plastic-surgery-disqualified-botox.jpg Invalid URL 'c_limit/camels-plastic-surgery-disqualified-botox.jpg': No schema supplied. Perhaps you meant http://c_limit/camels-plastic-surgery-disqualified-botox.jpg?\n",
      "Error http://www.oaklandzoo.org/WebApp-Images/Animals/Camel/Camel-2.jpg 'content-length'\n",
      "Error https://www.thenational.ae/image/policy:1.387269:1499549228/image/jpeg.jpg?f=16x9&w=1200&$p$f$w=dfa40e8 'content-length'\n",
      "Error imgsize-82012 Invalid URL 'imgsize-82012': No schema supplied. Perhaps you meant http://imgsize-82012?\n",
      "Error width-400 Invalid URL 'width-400': No schema supplied. Perhaps you meant http://width-400?\n",
      "Error resizemode-4/62279997.jpg Invalid URL 'resizemode-4/62279997.jpg': No schema supplied. Perhaps you meant http://resizemode-4/62279997.jpg?\n",
      "Error 0 Invalid URL '0': No schema supplied. Perhaps you meant http://0?\n",
      "Error 100 Invalid URL '100': No schema supplied. Perhaps you meant http://100?\n",
      "Error 430px Invalid URL '430px': No schema supplied. Perhaps you meant http://430px?\n",
      "Error https://asknature.org/wp-content/uploads/strategy/c1eb0f25d3e091f568ce26c0c6f8646f/camel_feature.jpg 'content-length'\n",
      "Error https://spana.org/wp-content/uploads/2016/04/DSC_0492-rotate.jpg 'content-length'\n"
     ]
    }
   ],
   "source": [
    "folder = 'camels'\n",
    "file = 'urls_camels.txt'\n",
    "\n",
    "path = Path(my_path+'data/mammals')\n",
    "\n",
    "dest = path/folder\n",
    "\n",
    "download_images(path/file, dest, max_pics=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'horses'\n",
    "file = 'urls_horses.txt'\n",
    "#file = 'horses.csv'\n",
    "\n",
    "path = Path(my_path+'data/mammals')\n",
    "\n",
    "dest = path/folder\n",
    "\n",
    "download_images(path/file, dest, max_pics=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/jupyter/tutorials/data/mammals/camels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jupyter/tutorials/data/mammals/camels | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/jupyter/tutorials/data/mammals/horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jupyter/tutorials/data/mammals/horses | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Let's take a look at some of our pictures then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['camels','horses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classes:\n",
    "    print(c)\n",
    "    verify_images(path/c, delete=True, max_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jupyter/tutorials/data/mammals/camels | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jupyter/tutorials/data/mammals/horses | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2, ds_tfms=get_transforms(), size=224, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path).ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(path/'models').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes, data.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start training our model. We will use a [convolutional neural network](http://cs231n.github.io/convolutional-networks/) backbone and a fully connected head with a single hidden layer as a classifier. Don't know what these things mean? Not to worry, we will dive deeper in the coming lessons. For the moment you need to know that we are building a model which will take images as input and will output the predicted probability for each of the categories (in this case, it will have 37 outputs).\n",
    "\n",
    "We will train for 4 epochs (4 cycles through all our data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, models.resnet34, metrics=error_rate)\n",
    "#learn = Learner.create_cnn(data, models.resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, models.resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(stop_div=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fit_one_cycle(2, max_lr=slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr=slice(1e-4,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the numbers represent:  \n",
    "prediction | actual | loss | probability it was predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(interp.plot_top_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreezing, fine-tuning, and learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model is working as we expect it to, we will *unfreeze* our model and train some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty accurate model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train in the same way as before but with one caveat: instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. Later in the course you can learn the details in the [resnet paper](https://arxiv.org/pdf/1512.03385.pdf)).\n",
    "\n",
    "Basically, resnet50 usually performs better because it is a deeper network with more parameters. Let's see if we can achieve a higher performance here. To help it along, let's us larger images too, since that way the network can see more detail. We reduce the batch size a bit since otherwise this larger network might eat up our GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = \"/home/jupyter/tutorials/data/mammals/\"\n",
    "fnames = [\"camels\", \"horses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=320, bs=bs//2)\n",
    "data.normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner.create_cnn(data, models.resnet50, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(8, max_lr=slice(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">It's astonishing that it's possible to recognize pet breeds so accurately! Let's see if full fine-tuning helps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it doesn't, so let's go back to our previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
